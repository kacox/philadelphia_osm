{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of OpenStreetMap data for Philadelphia, Pennsylvania.\n",
    "Kasey Cox, May 2017\n",
    "\n",
    "OSM XML file from MapZen.com Metro Extracts:\n",
    "https://mapzen.com/data/metro-extracts/metro/philadelphia_pennsylvania/101718083/Philadelphia/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Auditing\n",
    "\n",
    "Using __\"audit.py\"__ and __\"audit2.py\"__, I checked out the structure and contents of the data. The majority of problems were found in the tag attributes for the nodes, ways, and relations.\n",
    "\n",
    "### Tag \"k\" attributes\n",
    "\n",
    "Below gives the count of \"k\" attributes falling into predefined format categories.\n",
    "\n",
    "__`audit_k_formats(osmfile)` in \"audit.py\":__\n",
    "> `{'problemchars': 9, 'other': 182007, 'single_colon': 660267, 'lett_undrsc': 951883}`\n",
    ">\n",
    "> __'lett_undrsc'__ contains \"k\" attributes that only have lowercase letters and/or underscores.\n",
    ">\n",
    "> __'single_colon'__ contains \"k\" attributes with only lowercase letter and/or underscores on each side of a single colon\n",
    ">\n",
    "> __'problemchars'__ contains \"k\" attributes with problematic, special charaters like ?, quotes, or brackets.\n",
    ">\n",
    "> __'other'__ contains \"k\" attributes that do not fit into the above categories\n",
    "\n",
    "Here are some examples for 'problemchars' and 'other':\n",
    ">  __problemchars (all):__\n",
    ">\n",
    "> `set(['Price and Price Elder Law', 'tiger.source:tlid', 'fuel:2.14', 'max speed', 'store number', 'service area'])`\n",
    "> \n",
    "> __other (a few examples):__\n",
    ">\n",
    "> `set(['gnis:ST_alpha', 'gnis:County_num', 'gnis:ST_num', 'FIXME', 'gnis:Class', 'gnis:County', 'TODO'])`\n",
    "\n",
    "### Tag \"v\" attributes\n",
    "\n",
    "Below are the results from taking 2 different \"k\" values and using `audit_v_format(osmfile, kval)`. These results demonstrate the different formatting for the \"v\" values of the given \"k\"s.\n",
    "\n",
    "__`audit_v_format(osmfile, kval)`__ (in \"audit2.py\") (whilst limiting to the first 100,000 lines):\n",
    "> `'k'='addr:street'`\n",
    ">\n",
    "> `{'problemchars': 0, 'other': 0, 'whitespaces': 105, 'lett_undrsc': 0}`\n",
    "\n",
    "> `'k'='addr:postcode'`\n",
    ">\n",
    "> `{'problemchars': 0, 'other': 79, 'whitespaces': 0, 'lett_undrsc': 1}`\n",
    ">\n",
    "> - `'lett_undrsc'` contains any string with only letters and/or underscores\n",
    "> - `'whitespaces'` contains any string with whitespace characters\n",
    "> - `'problemchars'` contains any string with problematic characters like semi-colons, question marks, etc.\n",
    "> - `'other'` contains any string that doesn't fit into the above mentioned categories\n",
    "\n",
    "Much of the variation comes from (undesirable) inconcistencies and invalid data entry. This is demonstrated by exploring the data with __`audit_kv_pairs(osmfile, kval)`__ (in \"audit2.py\").\n",
    "\n",
    "`k='addr:street'`\n",
    "- inclusion of non-street address information\n",
    "    - South Clinton Avenue Ste. 111\n",
    "- abbreviations with inconsistent use of periods\n",
    "    - E. Mt Airy Ave\n",
    "    - Cooper St\n",
    "    - Wistar Rd.\n",
    "    - S 41st St\n",
    "    \n",
    "`k='addr:postcode'`\n",
    "- some postcodes have additional 4 digits\n",
    "    - 18940\n",
    "    - 19030-4005\n",
    "- invalid values\n",
    "    - PA\n",
    "    - '601 Stokes Road Medford, NJ 08055'\n",
    "    - 'NJ 08083'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit impressions so far\n",
    "Seeing the above makes it clear that there could be innumerable inconsistencies in such a large data set. I could spend a lot of time (days, weeks?) finding every inconsistency in every \"k\" attribute and \"v\" attribute. \n",
    "\n",
    "Additional subelements exist for ways (nd) and relations (member) that likely have the same problems as tags.\n",
    "\n",
    "It makes sense then to choose which \"k\" attributes are most valuable to my analysis and move forward with only those for cleaning and importing as a JSON file into Mongo DB.\n",
    "\n",
    "__I am going to stick to nodes for cleaning, exporting as a JSON file, and importing into MongoDB.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------\n",
    "## Cleaning, Exporting, Importing to MongoDB\n",
    "\n",
    "Prepared data for export as JSON file in the following format:\n",
    "```\n",
    "example_format =\n",
    "{\n",
    "    \"id\": \"2406124091\",\n",
    "    \"type\": \"node\",\n",
    "    \"created\": {\"version\":\"2\",\n",
    "               \"changeset\":\"17206049\",\n",
    "               \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
    "               \"user\":\"linuxUser16\",\n",
    "               \"uid\":\"1219059\"},\n",
    "    \"pos\": [41.9757030, -87.6921867],\n",
    "    \"address\": {\"housenumber\":\"5157\",\n",
    "               \"postcode\":\"60625\",\n",
    "               \"street\":\"North Lincoln Avenue\"},\n",
    "    \"amenity\": \"restaurant\",\n",
    "    \"cuisine\": \"Mexican\",\n",
    "    \"name\": \"La Cabana De Don Luis\",\n",
    "    \"phone\": \"1 (773)-271-5176\"\n",
    "}\n",
    "```\n",
    "\n",
    "The code in __\"clean.py\"__ contains all of the cleaning procedures performed on the data. This file also writes the cleaned information to a JSON file.\n",
    "\n",
    "Here is an overview of the cleaning performed:\n",
    "- All address components are checked for validity. If a value is not appropriate (e.g. \"PA\" in postalcode), \"Invalid\" is given.\n",
    "- Street prefixes are fixed (\"N\" becomes \"North\"; \"Mt\" becomes \"Mount\")\n",
    "- Street suffixes are fixed (\"St.\" or \"St\" becomes \"Street\")\n",
    "- The latitude and longitude are converted to floats and stored as a list in the key \"pos\".\n",
    "    \n",
    "I imported my cleaned JSON file into MongoDB using the mongoimport command in the terminal:\n",
    "> `mongoimport -d test -c osmdata --file philadelphia_pennsylvania.osm.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------\n",
    "## Queries\n",
    "\n",
    "```\n",
    "> db.osmdata.stats()\n",
    "{\n",
    "\t...,\n",
    "\t\"count\" : 3113088,\n",
    "\t\"size\" : 752185600,\n",
    "\t\"avgObjSize\" : 241,\n",
    "\t\"numExtents\" : 17,\n",
    "\t\"storageSize\" : 857440256,\n",
    "\t\"lastExtentSize\" : 227803136,\n",
    "\t...\n",
    "}\n",
    "```\n",
    "\n",
    "__Number of entries in collection__: 3,113,088 (since I only put node elements into the JSON file)\n",
    "\n",
    "\n",
    "Full code for the below queries is contained in __\"query.py\"__.\n",
    "\n",
    "### NUMBER OF UNIQUE USERS\n",
    "```\n",
    "user_query = [  {\"$group\": {\"_id\":\"$created.uid\", \"unique_users\": {\"$addToSet\":\"$_id\"}}},\n",
    "                {\"$project\":{\"_id\":0, \"total_users\":{\"$size\":\"$unique_users\"}}},\n",
    "                {\"$sort\":{\"total_users\":-1}},\n",
    "                {\"$limit\":1}\n",
    "             ]\n",
    "```\n",
    "__Results:__ \n",
    "> `{u'total_users': 764695}`\n",
    "\n",
    "### NUMBER OF SCHOOLS IN PHILADELPHIA\n",
    "\n",
    "After creating a text index:\n",
    "```\n",
    "school_query = [    {\"$match\":{\"$text\":{\"$search\":\"School\"}}},\n",
    "                    {\"$group\":{\"_id\":\"$address.city\", \"count\":{\"$sum\":1}}},\n",
    "                    {\"$match\": {\"$or\":[{\"_id\":\"Philadelphia\"}, {\"_id\":\"philadelphia\"}, {\"_id\":None}] }}\n",
    "               ]\n",
    "\n",
    "academy_query = [   {\"$match\":{\"$text\":{\"$search\":\"Academy\"}}},\n",
    "                    {\"$group\":{\"_id\":\"$address.city\", \"count\":{\"$sum\":1}}},\n",
    "                    {\"$match\": {\"$or\":[{\"_id\":\"Philadelphia\"}, {\"_id\":\"philadelphia\"}, {\"_id\":None}] }}\n",
    "                ]\n",
    "```\n",
    "\n",
    "__Results:__\n",
    "```\n",
    "Entries with \"School\"\n",
    "{u'count': 8, u'_id': u'Philadelphia'}\n",
    "{u'count': 1456, u'_id': None}\n",
    "{u'count': 1, u'_id': u'philadelphia'}\n",
    "\n",
    "Entries with \"Academy\"\n",
    "{u'count': 2, u'_id': u'Philadelphia'}\n",
    "{u'count': 106, u'_id': None}\n",
    "```\n",
    "\n",
    "__Comment:__\n",
    "> There are potentially Philadelphia schools in results that do not have a city tagged to it (None), too.\n",
    "\n",
    "### MOST POPULAR CUISINE\n",
    "```\n",
    "cuisine_query = [   {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},\n",
    "                    {\"$project\":{\"_id\":0, \"name\":\"$_id\", \"count\":\"$count\"}},\n",
    "                    {\"$sort\":{\"count\":-1}},\n",
    "                    {\"$limit\":10}\n",
    "                ]\n",
    "```\n",
    "\n",
    "__Result:__\n",
    "```\n",
    "{u'count': 3112260, u'name': None}\n",
    "{u'count': 155, u'name': u'pizza'}\n",
    "{u'count': 66, u'name': u'burger'}\n",
    "{u'count': 64, u'name': u'chinese'}\n",
    "{u'count': 62, u'name': u'coffee_shop'}\n",
    "{u'count': 57, u'name': u'italian'}\n",
    "{u'count': 54, u'name': u'sandwich'}\n",
    "...\n",
    "```\n",
    "\n",
    "__Comment:__\n",
    "Pizza is a type of Italian food. \"italian\" has 57 counts and \"pizza\" has 155. Italian cuisine comfortably leads the popularity list with 212 counts.\n",
    "\n",
    "\n",
    "### RESTAURANTS NEAREST TO THE AIRPORT:\n",
    "After creating a 2D index:\n",
    "```\n",
    "pos_query = [   {\"$geoNear\": {\"near\":[39.871944, -75.241111], \"distanceField\":\"dist.calculated\", \n",
    "                    \"query\": {\"amenity\": {\"$in\": [\"restaurant\", \"bar\", \"pub\", \"fast_food\", \"bar;pub\"] } }}},\n",
    "                {\"$limit\":1}\n",
    "            ]\n",
    "```\n",
    "\n",
    "__Result:__\n",
    "> {u'amenity': u'fast_food', u'dist': {u'calculated': 0.004474988617863642}, u'name': u\"Green Leaf's\", u'created': {u'changeset': u'34171919', u'version': u'1', u'user': u'dbaron', u'timestamp': u'2015-09-21T21:25:08Z', u'uid': u'481533'}, u'pos': [39.8754277, -75.2383022], u'_id': ObjectId('592c5021ab26e56b372c57a4'), u'type': u'node', u'id': u'3753512142'}\n",
    "\n",
    "__Comment:__\n",
    "> A quick Google map search confirms that Green Leaf's is a restaurant nearby Philadelphia International Airport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------------\n",
    "## Comments\n",
    "\n",
    "In working with this data, I saw a great need for fuller tagging of nodes. Many nodes are relatively incomplete: I found many nodes that were schools by name, but were not tagged as such with the amenity field. Along these lines, when auditing the data I would see addresses that were incomplete -- there would be a city name but no postcode, etc. The data would be much better if there were a minimum requirement set by OpenStreetMap when users submit nodes. For example, make the full address (house or building number, street name, city/town, state, postcode) required if it is a place, as well as at least one other tag (like \"amenity\" or \"place\" or \"name\").\n",
    "\n",
    "When cleaning the data, I also noticed another way OSM could improve user submissions. I found situations where invalid information was in a field (for example, \"PA\" in the \"postcode\" field). OSM could implement simple checks to increase the chances of valid information being submitted. This would make cleaning easier and subsequent analysis more meaningful.\n",
    "\n",
    "_Benefits:_ Address information will be more complete; nodes will have more tags completed; tag values will contain fewer to no invalid information.\n",
    "\n",
    "_Anticipated problems:_ Contributors may skip filling in information if they do not know all of the required components; requires participation from contributors.\n",
    "\n",
    "Another potential way to flesh out the data would be to collaborate with Uber or Lyft. These applications contain a wealth of geographic information. Not only could you use the information they already have to populate nodes, ways, and relations, but add new locales or details as well. When a customer requests a ride and gives the desired destination, you could have fields in the application where details could be entered by the customer if they don't already exist for the destination (like name, kind of amenity or place, is it BYOB, etc).\n",
    "\n",
    "Benefits: Potential for many more people to contribute to the data; data has the opportunity to be corrected or added to; contribution will be tied to a location; earlier mentioned validity checks can be implemented.\n",
    "\n",
    "Anticipated problems: Requires participation from contributors; contributors might not like being asked to contribute."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
